{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "\n",
      "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
      "\n",
      "  Please upgrade your code to TensorFlow 2.0:\n",
      "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
      "\n",
      "  Or install the latest stable TensorFlow 1.X release:\n",
      "    * `pip install -U \"tensorflow==1.*\"`\n",
      "\n",
      "  Otherwise your code may be broken by the change.\n",
      "\n",
      "  \n",
      "WARNING:tensorflow:From c:\\github\\openai\\spinningup\\spinup\\utils\\mpi_tf.py:29: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Box(35,)\n",
      "Box(3,)\n",
      "WARNING:tensorflow:From c:\\github\\openai\\spinningup\\spinup\\algos\\ppo\\core.py:14: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\github\\openai\\spinningup\\spinup\\algos\\ppo\\core.py:31: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import time\n",
    "import spinup.algos.ppo.core as core\n",
    "from spinup.utils.logx import EpochLogger\n",
    "import spinup.algos.ppo.ppo as ppo\n",
    "from tensorflow.train import AdamOptimizer\n",
    "from spinup.utils.logx import restore_tf_graph\n",
    "from os import path\n",
    "\n",
    "train_mode = 'locomotion'\n",
    "hidden_sizes = (256, 256)\n",
    "#train_mode = 'sense'\n",
    "#hidden_sizes = (32,32)\n",
    "env = gym.make('zrc_learn:zrc-v0', train_mode=train_mode)\n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "\n",
    "env.reset()\n",
    "\n",
    "x_ph, a_ph = core.placeholders_from_spaces(env.observation_space, env.action_space)\n",
    "adv_ph, ret_ph, logp_old_ph = core.placeholders(None, None, None)\n",
    "ac_kwargs = {'action_space': env.action_space, 'hidden_sizes':hidden_sizes}\n",
    "pi, logp, logp_pi, v = core.mlp_actor_critic(x_ph, a_ph, **ac_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Log dir locomotion already exists! Storing info there anyway.\n",
      "\u001b[32;1mLogging data to locomotion\\progress.txt\u001b[0m\n",
      "\u001b[32;1m\n",
      "Number of parameters: \t pi: 75782, \t v: 75265\n",
      "\u001b[0m\n",
      "WARNING:tensorflow:From <ipython-input-2-47a3fc37fe8d>:27: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "obs_dim = env.observation_space.shape\n",
    "act_dim = env.action_space.shape\n",
    "steps_per_epoch = 12000\n",
    "epochs = 1000\n",
    "gamma=0.99\n",
    "clip_ratio=0.2\n",
    "pi_lr=3e-4\n",
    "vf_lr=1e-3\n",
    "train_pi_iters=80\n",
    "train_v_iters=80\n",
    "lam=0.97\n",
    "max_ep_len=12000\n",
    "target_kl=0.02 #0.01\n",
    "save_freq=10\n",
    "\n",
    "log = EpochLogger(output_dir=train_mode)\n",
    "\n",
    "# Experience buffer\n",
    "buf = ppo.PPOBuffer(obs_dim, act_dim, steps_per_epoch, gamma, lam)\n",
    "\n",
    "# Count variables\n",
    "var_counts = tuple(core.count_vars(scope) for scope in ['pi', 'v'])\n",
    "log.log('\\nNumber of parameters: \\t pi: %d, \\t v: %d\\n'%var_counts)\n",
    "\n",
    "# PPO objectives\n",
    "ratio = tf.exp(logp - logp_old_ph)          # pi(a|s) / pi_old(a|s)\n",
    "min_adv = tf.where(adv_ph>0, (1+clip_ratio)*adv_ph, (1-clip_ratio)*adv_ph)\n",
    "pi_loss = -tf.reduce_mean(tf.minimum(ratio * adv_ph, min_adv))\n",
    "v_loss = tf.reduce_mean((ret_ph - v)**2)\n",
    "\n",
    "# Optimizers\n",
    "train_pi = AdamOptimizer(learning_rate=pi_lr).minimize(pi_loss)\n",
    "train_v = AdamOptimizer(learning_rate=vf_lr).minimize(v_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': {'x': 'Placeholder:0'}, 'outputs': {'pi': 'pi/add:0', 'v': 'v/Squeeze:0'}}\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "log.setup_tf_saver(sess, inputs={'x': x_ph}, outputs={'pi': pi, 'v': v})\n",
    "print(log.tf_saver_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    inputs = {k:v for k,v in zip(all_phs, buf.get())}\n",
    "    pi_l_old, v_l_old, ent = sess.run([pi_loss, v_loss, approx_ent], feed_dict=inputs)\n",
    "\n",
    "    # Training\n",
    "    for i in range(train_pi_iters):\n",
    "        _, kl = sess.run([train_pi, approx_kl], feed_dict=inputs)\n",
    "        if kl > 1.5 * target_kl:\n",
    "            log.log('Early stopping at step %d due to reaching max kl.'%i)\n",
    "            break\n",
    "    log.store(StopIter=i)\n",
    "    for _ in range(train_v_iters):\n",
    "        sess.run(train_v, feed_dict=inputs)\n",
    "\n",
    "    # Log changes from update\n",
    "    pi_l_new, v_l_new, kl, cf = sess.run([pi_loss, v_loss, approx_kl, clipfrac], feed_dict=inputs)\n",
    "    log.store(LossPi=pi_l_old, LossV=v_l_old, \n",
    "                 KL=kl, Entropy=ent, ClipFrac=cf,\n",
    "                 DeltaLossPi=(pi_l_new - pi_l_old),\n",
    "                 DeltaLossV=(v_l_new - v_l_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 1206 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "WARNING:tensorflow:From c:\\github\\openai\\spinningup\\spinup\\utils\\logx.py:226: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: locomotion\\simple_save\\saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |               0 |\n",
      "|      AverageEpRet |            11.5 |\n",
      "|          StdEpRet |             1.1 |\n",
      "|          MaxEpRet |            12.4 |\n",
      "|          MinEpRet |            9.95 |\n",
      "|             EpLen |         3.6e+03 |\n",
      "|      AverageVVals |               0 |\n",
      "|          StdVVals |               0 |\n",
      "|          MaxVVals |               0 |\n",
      "|          MinVVals |               0 |\n",
      "| TotalEnvInteracts |         1.2e+04 |\n",
      "|            LossPi |       -8.27e-08 |\n",
      "|             LossV |            3.21 |\n",
      "|       DeltaLossPi |        -0.00118 |\n",
      "|        DeltaLossV |           -0.08 |\n",
      "|           Entropy |            2.77 |\n",
      "|                KL |         0.00464 |\n",
      "|          ClipFrac |          0.0433 |\n",
      "|          StopIter |              79 |\n",
      "|              Time |            29.6 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 1206 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               1 |\n",
      "|      AverageEpRet |            14.4 |\n",
      "|          StdEpRet |            3.95 |\n",
      "|          MaxEpRet |              20 |\n",
      "|          MinEpRet |            11.3 |\n",
      "|             EpLen |         3.6e+03 |\n",
      "|      AverageVVals |           0.281 |\n",
      "|          StdVVals |        2.98e-08 |\n",
      "|          MaxVVals |           0.281 |\n",
      "|          MinVVals |           0.281 |\n",
      "| TotalEnvInteracts |         2.4e+04 |\n",
      "|            LossPi |       -1.39e-07 |\n",
      "|             LossV |            4.52 |\n",
      "|       DeltaLossPi |        -0.00217 |\n",
      "|        DeltaLossV |         -0.0327 |\n",
      "|           Entropy |            2.73 |\n",
      "|                KL |         0.00569 |\n",
      "|          ClipFrac |          0.0597 |\n",
      "|          StopIter |              79 |\n",
      "|              Time |            58.7 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 1206 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               2 |\n",
      "|      AverageEpRet |            3.33 |\n",
      "|          StdEpRet |            4.71 |\n",
      "|          MaxEpRet |              10 |\n",
      "|          MinEpRet |               0 |\n",
      "|             EpLen |         3.6e+03 |\n",
      "|      AverageVVals |           0.521 |\n",
      "|          StdVVals |           0.216 |\n",
      "|          MaxVVals |            1.94 |\n",
      "|          MinVVals |          0.0347 |\n",
      "| TotalEnvInteracts |         3.6e+04 |\n",
      "|            LossPi |        1.25e-06 |\n",
      "|             LossV |           0.651 |\n",
      "|       DeltaLossPi |        -0.00416 |\n",
      "|        DeltaLossV |          -0.239 |\n",
      "|           Entropy |            2.75 |\n",
      "|                KL |           0.014 |\n",
      "|          ClipFrac |           0.155 |\n",
      "|          StopIter |              79 |\n",
      "|              Time |            87.9 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 1206 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               3 |\n",
      "|      AverageEpRet |           -6.62 |\n",
      "|          StdEpRet |            4.68 |\n",
      "|          MaxEpRet |               0 |\n",
      "|          MinEpRet |             -10 |\n",
      "|             EpLen |         3.6e+03 |\n",
      "|      AverageVVals |          0.0918 |\n",
      "|          StdVVals |               0 |\n",
      "|          MaxVVals |          0.0918 |\n",
      "|          MinVVals |          0.0918 |\n",
      "| TotalEnvInteracts |         4.8e+04 |\n",
      "|            LossPi |       -2.82e-07 |\n",
      "|             LossV |            2.41 |\n",
      "|       DeltaLossPi |        -0.00192 |\n",
      "|        DeltaLossV |         -0.0574 |\n",
      "|           Entropy |            2.71 |\n",
      "|                KL |         0.00614 |\n",
      "|          ClipFrac |          0.0448 |\n",
      "|          StopIter |              79 |\n",
      "|              Time |             117 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 1206 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               4 |\n",
      "|      AverageEpRet |            16.7 |\n",
      "|          StdEpRet |            9.43 |\n",
      "|          MaxEpRet |              30 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |         3.6e+03 |\n",
      "|      AverageVVals |          -0.151 |\n",
      "|          StdVVals |        2.98e-08 |\n",
      "|          MaxVVals |          -0.151 |\n",
      "|          MinVVals |          -0.151 |\n",
      "| TotalEnvInteracts |           6e+04 |\n",
      "|            LossPi |        1.65e-07 |\n",
      "|             LossV |            2.93 |\n",
      "|       DeltaLossPi |        -0.00167 |\n",
      "|        DeltaLossV |           -0.32 |\n",
      "|           Entropy |            2.63 |\n",
      "|                KL |         0.00385 |\n",
      "|          ClipFrac |          0.0443 |\n",
      "|          StopIter |              79 |\n",
      "|              Time |             147 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_action_ops = [pi, v, logp_pi]\n",
    "all_phs = [x_ph, a_ph, adv_ph, ret_ph, logp_old_ph]\n",
    "\n",
    "# Info (useful to watch during learning)\n",
    "approx_kl = tf.reduce_mean(logp_old_ph - logp)      # a sample estimate for KL-divergence, easy to compute\n",
    "approx_ent = tf.reduce_mean(-logp)                  # a sample estimate for entropy, also easy to compute\n",
    "clipped = tf.logical_or(ratio > (1+clip_ratio), ratio < (1-clip_ratio))\n",
    "clipfrac = tf.reduce_mean(tf.cast(clipped, tf.float32))\n",
    "\n",
    "#if (path.exists('log/simple_save/saved_model.pb')):\n",
    "#        tf.saved_model.loader.load(\n",
    "#                sess,\n",
    "#                [tf.saved_model.tag_constants.SERVING],\n",
    "#                'log/simple_save'\n",
    "#            )\n",
    "\n",
    "start_time = time.time()\n",
    "o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "\n",
    "env.render()\n",
    "\n",
    "# Main loop: collect experience in env and update/log each epoch\n",
    "for epoch in range(epochs):\n",
    "    for t in range(steps_per_epoch):\n",
    "        a, v_t, logp_t = sess.run(get_action_ops, feed_dict={x_ph: o.reshape(1,-1)})\n",
    "\n",
    "        # save and log\n",
    "        buf.store(o, a, r, v_t, logp_t)\n",
    "        log.store(VVals=v_t)\n",
    "\n",
    "        o, r, d, _ = env.step(a[0])\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "\n",
    "        terminal = d or (ep_len == max_ep_len)\n",
    "        if terminal or (t==steps_per_epoch-1):\n",
    "            if not(terminal):\n",
    "                print('Warning: trajectory cut off by epoch at %d steps.'%ep_len)\n",
    "            # if trajectory didn't reach terminal state, bootstrap value target\n",
    "            last_val = r if d else sess.run(v, feed_dict={x_ph: o.reshape(1,-1)})\n",
    "            buf.finish_path(last_val)\n",
    "            if terminal:\n",
    "                # only save EpRet / EpLen if trajectory finished\n",
    "                log.store(EpRet=ep_ret, EpLen=ep_len)\n",
    "            o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "\n",
    "    # Save model\n",
    "    if (epoch % save_freq == 0) or (epoch == epochs-1):\n",
    "        log.save_state({'env': env}, None)\n",
    "\n",
    "    # Perform PPO update!\n",
    "    update()\n",
    "\n",
    "    # Log info about epoch\n",
    "    log.log_tabular('Epoch', epoch)\n",
    "    log.log_tabular('EpRet', with_min_and_max=True)\n",
    "    log.log_tabular('EpLen', average_only=True)\n",
    "    log.log_tabular('VVals', with_min_and_max=True)\n",
    "    log.log_tabular('TotalEnvInteracts', (epoch+1)*steps_per_epoch)\n",
    "    log.log_tabular('LossPi', average_only=True)\n",
    "    log.log_tabular('LossV', average_only=True)\n",
    "    log.log_tabular('DeltaLossPi', average_only=True)\n",
    "    log.log_tabular('DeltaLossV', average_only=True)\n",
    "    log.log_tabular('Entropy', average_only=True)\n",
    "    log.log_tabular('KL', average_only=True)\n",
    "    log.log_tabular('ClipFrac', average_only=True)\n",
    "    log.log_tabular('StopIter', average_only=True)\n",
    "    log.log_tabular('Time', time.time()-start_time)\n",
    "    log.dump_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spinup.utils.test_policy import load_policy, run_policy\n",
    "\n",
    "#x, ga = load_policy('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import time\n",
    "import spinup.algos.ppo.core as core\n",
    "from spinup.utils.logx import EpochLogger\n",
    "import spinup.algos.ppo.ppo as ppo\n",
    "from tensorflow.train import AdamOptimizer\n",
    "from spinup.utils.logx import restore_tf_graph\n",
    "from os import path\n",
    "\n",
    "sess = tf.Session()\n",
    "model = restore_tf_graph(sess, osp.join('locomotion', 'simple_save'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
